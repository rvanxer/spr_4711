{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45eaa0ac-e3a3-4072-8dd9-c7abc31d3d76",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f900d4f7-b206-430a-9196-39af62f7247b",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/umni2/a/umnilab/users/verma99/mk/spr_4711/code\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800e40e0-c716-4e1b-8d0c-878d421fc327",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "605761e2",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import contextily as ctx\n",
    "import fiona\n",
    "import osmnx\n",
    "import shapely\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4664b67e-d0f5-41a5-be3b-d99003ca5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53ade898",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/19 11:20:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "SP.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b983008-30e2-4435-8269-75b4fd3bbbdf",
   "metadata": {},
   "source": [
    "## Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54cfd9c2-41d2-4c28-bb56-424a8e2d354f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# spatial scales of the maps\n",
    "SCALES = ['BG', 'County', 'Tract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36dd4888-e440-4763-9105-0f19b0b0d005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# travel modes considered\n",
    "MODES = ['Bicycling', 'Driving', 'Transit', 'Walking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0207f91f-5040-477d-8ba7-3c825b050ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# travel time thresholds (in minutes)\n",
    "TRAVEL_TIMES = [15, 30, 45, 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8bc474",
   "metadata": {},
   "source": [
    "# Regional boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bd592f",
   "metadata": {},
   "source": [
    "## Download data\n",
    "Note that the TIGER/LINE boundaries and ACS data of the subdivisions of Indiana at different scales were already downloaded in [../../spr_4608/code/1_Geometry_ACS.ipynb](../../spr_4608/code/1_Geometry_ACS.ipynb), but they were for the year 2020 (I think). The files were then directly copied from `$MK/spr_4608/data/geometry` to `$MK/spr_4711/data/acs`.\n",
    "\n",
    "However, since the UMN access data used the 2010 definitions, they are downloaded explicitly from the Census website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c92d9038",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def download_tiger_boundary(scale, year=2010, state='Indiana', save=True, overwrite=False):\n",
    "    scale = scale.lower()\n",
    "    assert scale in ['tabblock', 'bg', 'taz', 'tract', 'county', 'cbsa']\n",
    "    outfile = P.data / f'boundary/{scale}.parquet'\n",
    "    if outfile.exists() and not overwrite:\n",
    "        return\n",
    "    print('Downloading zones at scale:', scale)\n",
    "    fips = mk.geo.US_STATES_FIPS[state.upper()]\n",
    "    year_label = str(year % 2000)\n",
    "    url = (f'https://www2.census.gov/geo/pvs/tiger{year}st/{fips}_{state}/'\n",
    "           f'{fips}/tl_{year}_{fips}_{scale}{year_label}.zip')\n",
    "    if scale == 'taz': url = url.replace('tl_2010', 'tl_2011')\n",
    "    zipfile = P.data / f'tiger_boundary_{scale}.zip'\n",
    "    urllib.request.urlretrieve(url, zipfile)\n",
    "    df = gpd.read_file(zipfile).to_crs(CRS_DEG)\n",
    "    df = df.rename(columns=lambda x: x.lower().replace(year_label, ''))\n",
    "    if 'nameslad' in df.columns:\n",
    "        df = (df.drop(columns='name', errors='ignore')\n",
    "              .rename(columns={'namelsad': 'name'}))\n",
    "    cols = ['geoid','name','aland','awater','geometry']\n",
    "    if 'name' not in df.columns: cols.pop(1)\n",
    "    df = df[cols]\n",
    "    if save: df.to_parquet(U.mkfile(outfile))\n",
    "    zipfile.unlink()\n",
    "    return df\n",
    "\n",
    "# download_tiger_boundary('County')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95af0201",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2899ac8deec49eea4728fe134c622dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# t=2:14\n",
    "for scale in tqdm(['County', 'Tract', 'BG', 'TabBlock', 'CBSA', 'TAZ']):\n",
    "    download_tiger_boundary(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da79eb74",
   "metadata": {},
   "source": [
    "## Combine scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aed4d6f1-256d-4b0e-ac35-e547974de037",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,417 rows x 6 cols; Memory: 1.4 MiB; CRS: EPSG:4326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid</th>\n",
       "      <th>aland</th>\n",
       "      <th>awater</th>\n",
       "      <th>geometry</th>\n",
       "      <th>scale</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>&lt;category&gt;</td>\n",
       "      <td>&lt;int64&gt;</td>\n",
       "      <td>&lt;int64&gt;</td>\n",
       "      <td>&lt;geometry&gt;</td>\n",
       "      <td>&lt;object&gt;</td>\n",
       "      <td>&lt;object&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181379685003</td>\n",
       "      <td>2566010</td>\n",
       "      <td>39626</td>\n",
       "      <td>POLYGON ((-85.20815 39.304011, -85.208134 39.3...</td>\n",
       "      <td>BG</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          geoid    aland   awater  \\\n",
       "     <category>  <int64>  <int64>   \n",
       "0  181379685003  2566010    39626   \n",
       "\n",
       "                                            geometry     scale      name  \n",
       "                                          <geometry>  <object>  <object>  \n",
       "0  POLYGON ((-85.20815 39.304011, -85.208134 39.3...        BG       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bound = pd.concat([\n",
    "    gpd.read_parquet(P.data / f'boundary/{scale.lower()}.parquet')\n",
    "    .assign(scale=scale) for scale in SCALES\n",
    "]).astype({'geoid': 'category'}).reset_index(drop=True).set_crs(CRS_DEG).disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a527e843-a56d-4fab-b7c2-10b70bdbefd9",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# bound.to_parquet(P.data / 'export/boundary.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d440d89-7054-42a3-a6e2-808392f176c8",
   "metadata": {},
   "source": [
    "# AAA\n",
    "**Access Across America (AAA)** from [**Accessibility Observatory**](https://ao.umn.edu/) at the University of Minnesota\n",
    "\n",
    "* **[Available datasets](https://ao.umn.edu/data/datasets)**\n",
    "* **[Methodology report for transit access](https://ao.umn.edu/research/america/transit/2019/documents/AccessAcrossAmerica-Transit2019-Methodology.pdf)**\n",
    "* **[Transit data documentation](https://conservancy.umn.edu/bitstream/handle/11299/218072/2019DataDoc_all_LEHD.pdf?sequence=51&isAllowed=y)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f281932-8a36-4770-99b9-8729a6fe6e4a",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3efc4c6-85e7-40ac-9579-19b4fcd9d8da",
   "metadata": {},
   "source": [
    "### [Auto (2018)](https://conservancy.umn.edu/handle/11299/211408)\n",
    "Data not available for Indiana ðŸ˜­"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc53629e-48f4-4a31-8c42-d12ff063f467",
   "metadata": {},
   "source": [
    "### [Transit (2019)](https://conservancy.umn.edu/handle/11299/218072)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ffa08e6a-295e-4c33-ac67-15d72feaf1ba",
   "metadata": {},
   "source": [
    "%%bash\n",
    "dir='../data/aaa/transit'\n",
    "mkdir -p $dir; cd $dir\n",
    "fname='IN_transit_accessibility_data_2019_geopackage.zip?sequence=68'\n",
    "wget https://conservancy.umn.edu/bitstream/handle/11299/218072/$fname&isAllowed=y\n",
    "unzip $fname\n",
    "rm $fname *.pdf *.txt\n",
    "mv IN_tr_2019_0700-0859-avg.gpkg indiana.gpkg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89db7ea8-1422-40cd-95ef-fd1f80b2949c",
   "metadata": {},
   "source": [
    "### [Bike (2019)](https://conservancy.umn.edu/handle/11299/218194)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "754d77b1-3c2d-40dc-8212-a486bfde4001",
   "metadata": {},
   "source": [
    "%%bash\n",
    "dir='../data/aaa/bike'\n",
    "mkdir -p $dir; cd $dir\n",
    "fname='IN_bike_accessibility_data_2019.zip?sequence=70'\n",
    "wget https://conservancy.umn.edu/bitstream/handle/11299/218194/$fname/&isAllowed=y\n",
    "unzip \"$fname%2F&isAllowed=y\"\n",
    "unzip IN_bike_accessibility_data_2019_lts4.zip\n",
    "rm $fname *.zip *.pdf *.txt\n",
    "mv IN_bi_2019_1200_lts4.gpkg indiana.gpkg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5bd11c-915b-4546-8adc-80df9b008083",
   "metadata": {},
   "source": [
    "### [Walk (2014)](https://conservancy.umn.edu/handle/11299/173991)\n",
    "Only available for Indianapolis region"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f12985f-fbea-4543-9a8f-e1895cde2f0f",
   "metadata": {},
   "source": [
    "%%bash\n",
    "dir='../data/aaa/walk'\n",
    "mkdir -p $dir; cd $dir\n",
    "fname='26900_wa_2014_0700-0700.zip?sequence=38&isAllowed=y'\n",
    "wget \"https://conservancy.umn.edu/bitstream/handle/11299/173991/$fname\"\n",
    "unzip $fname\n",
    "rm $fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab92012-d9f1-4553-a765-70ec28964ff2",
   "metadata": {},
   "source": [
    "## Extract layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "505476b2-c516-4fca-8dc0-7958a4c78b8e",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_aaa_layers(mode, year=2017):\n",
    "    mode = mode.lower()\n",
    "    assert mode in ['bike', 'transit']\n",
    "    fpath = P.data / f'aaa/{mode}/indiana.gpkg'\n",
    "    year = str(year % 2000)\n",
    "    for layer in tqdm(fiona.listlayers(fpath)):\n",
    "        if not layer.startswith(mode[:2] + '_'): continue\n",
    "        tt = int(layer.split('_')[1])\n",
    "        df = gpd.read_file(fpath, layer=layer).astype({'blockid': int})\n",
    "        df = df.set_index('blockid').rename_axis('geoid')\n",
    "        df = df.filter(like=f'_{year}').astype(np.int32)\n",
    "        df = df.rename(columns=lambda x: x.replace(f'_{year}', ''))\n",
    "        df.to_parquet(P.data / f'aaa/{mode}/{tt:02}_min.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5c61f40-9952-4430-872b-0adb28df9c30",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# %time x = get_aaa_layers('bike'); x # t=8:32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35b023b9-e1b9-4e45-b15f-5f8b1387ef88",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# get_aaa_layers('transit') # t=9:16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a49e101-c439-4177-b3bc-a2d7dc811a07",
   "metadata": {},
   "source": [
    "## Get useful info\n",
    "**[Columns documentation](https://conservancy.umn.edu/bitstream/handle/11299/218072/2019DataDoc_all_LEHD.pdf?sequence=51&isAllowed=y)**\n",
    "\n",
    "Chosen variables described in a YAML file: `{P.data}/aaa/lehd_variables.yml`.\n",
    "\n",
    "Description of LODES columns: https://lehd.ces.census.gov/data/lodes/LODES7/LODESTechDoc7.4.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b14d79cd-3466-4c3a-9824-de59ecfb5f18",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "with open(P.data / 'aaa/lehd_variables.yml', 'rb') as f:\n",
    "    lehd_cat_vars = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab984ef8-14ec-448d-a7be-9b40558c051c",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_aaa_tables(scale, mode, tt_thresh, cat_vars=lehd_cat_vars):\n",
    "    fpath = P.data / f'aaa/{mode.lower()}/{tt_thresh:02}_min.parquet'\n",
    "    df = pd.read_parquet(fpath)\n",
    "    digits = {'Block': 15, 'BG': 12, 'Tract': 11, 'County': 5}[scale]\n",
    "    df.index = df.index.astype(str).str.slice(0, digits).rename('geoid')\n",
    "    df = df.groupby('geoid').sum().astype(np.int32)\n",
    "    res = []\n",
    "    for is_rac, prefix in [(False, 'w_'), (True, 'r_')]:\n",
    "        res.append(df.filter(like=prefix).reset_index()\n",
    "                   .rename(columns=lambda x: x.replace(prefix, ''))\n",
    "                   .assign(**{'is_rac': is_rac}))\n",
    "    df = (pd.concat(res).set_index(['is_rac', 'geoid'])\n",
    "          .fillna(0).astype(np.int32))\n",
    "    res = []\n",
    "    for cat, codes2vars in cat_vars.items():\n",
    "        d = df[codes2vars.keys()].rename(columns=codes2vars).reset_index()\n",
    "        d = d.melt(['is_rac', 'geoid'], var_name='subcategory', value_name='num_jobs')\n",
    "        d['category'] = cat\n",
    "        res.append(d)\n",
    "    df = (pd.concat(res).reset_index(drop=True)\n",
    "          [['is_rac', 'category', 'subcategory', 'geoid', 'num_jobs']])\n",
    "    return df\n",
    "\n",
    "# %time x = get_aaa_tables('Tract', 'Transit', 30); x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df69da3-bbd0-47d1-9eac-08236ea5a3da",
   "metadata": {},
   "source": [
    "## Prepare a single file for export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "057ca583-4eda-43f6-bd02-dd0adfe9a52b",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------+------+--------+-----------+------------+--------+\n",
      "|scale|     mode|tt_thresh|is_rac|category|subcategory|       geoid|num_jobs|\n",
      "+-----+---------+---------+------+--------+-----------+------------+--------+\n",
      "|   BG|Bicycling|       15| false| Overall|      Total|180010301001|     154|\n",
      "+-----+---------+---------+------+--------+-----------+------------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_aaa_overall(scales=SCALES, modes=('Bike', 'Transit'), travel_times=TRAVEL_TIMES,\n",
    "                    save=True, overwrite=False):\n",
    "    outfile = P.data / 'export/aaa.parquet'\n",
    "    if outfile.exists() and not overwrite:\n",
    "        return SP.read_parquet(outfile)\n",
    "    res = []\n",
    "    for scale in tqdm(scales):\n",
    "        for mode in modes:\n",
    "            for tt in travel_times:\n",
    "                df = get_aaa_tables(scale, mode, tt)\n",
    "                mode2 = 'Bicycling' if mode == 'Bike' else mode\n",
    "                df = df.assign(mode=mode2, scale=scale, tt_thresh=tt)\n",
    "                res.append(df)\n",
    "    df = pd.concat(res).reset_index(drop=True)\n",
    "    df = df.astype({x: 'category' for x in [\n",
    "        'category', 'subcategory', 'geoid', 'mode', 'scale', 'tt_thresh']})\n",
    "    df = df[['scale', 'mode', 'tt_thresh', 'is_rac',\n",
    "             'category', 'subcategory', 'geoid', 'num_jobs']]\n",
    "    if save:\n",
    "        df.to_parquet(U.mkfile(outfile))\n",
    "    return df\n",
    "\n",
    "%time aaa = get_aaa_overall(overwrite=0).disp() # t=1:51"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf9daed",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EPA EJ Screening Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a489a9",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3450b5b2",
   "metadata": {},
   "source": [
    "Download links taken from https://gaftp.epa.gov/EJSCREEN/2022 (directed from the [Download page](https://www.epa.gov/ejscreen/download-ejscreen-data))."
   ]
  },
  {
   "cell_type": "raw",
   "id": "43162618-e236-4ae7-b727-9ab6a0c954f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%bash\n",
    "dir=../data/ejscreen\n",
    "mkdir dir && cd dir\n",
    "wget --no-check-certificate https://gaftp.epa.gov/EJScreen/2023/EJSCREEN_2023_BG_Columns.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28d00198-7292-4df0-94f5-10b5ca71e95c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_tract = 'https://gaftp.epa.gov/EJScreen/2023/EJSCREEN_2023_Tracts_StatePct_with_AS_CNMI_GU_VI.csv.zip'\n",
    "url_bg = 'https://gaftp.epa.gov/EJScreen/2023/EJSCREEN_2023_BG_StatePct_with_AS_CNMI_GU_VI.csv.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4cd3e76-4099-43e5-b731-73fb7d04b196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_epa_ejs(url, fname, unzip=False, overwrite=False):\n",
    "    root = U.mkdir(P.data / 'ejscreen')\n",
    "    zipped = root / f'{fname}.csv.zip'\n",
    "    csv = root / f'{fname}.csv'\n",
    "    if csv.exists() and not overwrite:\n",
    "        return\n",
    "    urllib.request.urlretrieve(url, zipped)\n",
    "    if unzip:\n",
    "        fname = url.split('/')[-1].replace('.zip', '')\n",
    "        with ZipFile(zipped, 'r') as f:\n",
    "            f.extract(fname, path=root)\n",
    "        (root / fname).rename(csv)\n",
    "        zipped.unlink()\n",
    "    \n",
    "# %time download_epa_ejs(url_tract, 'tract2023', unzip=1) # t=0:06\n",
    "# %time download_epa_ejs(url_bg, 'bg2023', unzip=1) # t=0:23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e714f9c6",
   "metadata": {},
   "source": [
    "## Clean data\n",
    "The list of all columns in the EJS data files was downloaded from the server ([link to Excel file](https://gaftp.epa.gov/EJScreen/2023/EJSCREEN_2023_BG_Columns.xlsx)). The columns relevant to the transport equity dashboard were manually identified from this file and stored in `{P.data}/ejscreen/variables.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e61cd140-8f7b-4708-bf0c-b926608e4a82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 rows x 5 cols; Memory: 0.0 MiB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_ses</th>\n",
       "      <th>is_derived</th>\n",
       "      <th>is_pctile</th>\n",
       "      <th>code</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>&lt;bool&gt;</td>\n",
       "      <td>&lt;bool&gt;</td>\n",
       "      <td>&lt;bool&gt;</td>\n",
       "      <td>&lt;object&gt;</td>\n",
       "      <td>&lt;object&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ACSTOTPOP</td>\n",
       "      <td>Total: Population</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ACSIPOVBAS</td>\n",
       "      <td>Total: Eligible poverty status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ACSEDUCBAS</td>\n",
       "      <td>Total: 25 years and over</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_ses is_derived is_pctile        code                        variable\n",
       "   <bool>     <bool>    <bool>    <object>                        <object>\n",
       "0    True      False     False   ACSTOTPOP               Total: Population\n",
       "1    True      False     False  ACSIPOVBAS  Total: Eligible poverty status\n",
       "2    True      False     False  ACSEDUCBAS        Total: 25 years and over"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ejs_vars = pd.read_csv(P.data / 'ejscreen/variables.csv').disp(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a073ac47",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----------+---------+-----------------+-----------+------+\n",
      "|scale|is_ses|is_derived|is_pctile|         variable|      geoid| value|\n",
      "+-----+------+----------+---------+-----------------+-----------+------+\n",
      "|Tract|  true|     false|    false|Total: Population|18001030100|4826.0|\n",
      "+-----+------+----------+---------+-----------------+-----------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean_ejs_data(cols=ejs_vars, year=2023, scales=['Tract', 'BG'], state='Indiana',\n",
    "                   save=True, overwrite=False):\n",
    "    outpath = P.data / f'export/ejs.parquet'\n",
    "    if outpath.exists() and not overwrite:\n",
    "        return SP.read_parquet(outpath)\n",
    "    res = []\n",
    "    for scale in scales:\n",
    "        file = P.data / f'ejscreen/{scale.lower()}{year}.csv'\n",
    "        df = pd.read_csv(file, usecols=['ID', 'STATE_NAME'] + cols['code'].tolist())\n",
    "        df = df.query(f'STATE_NAME == \"{state}\"').drop(columns='STATE_NAME')\n",
    "        df = df.melt('ID', var_name='code').merge(cols, on='code').drop(columns='code')\n",
    "        df = df.rename(columns={'ID': 'geoid'}).astype({'geoid': str, 'value': float})\n",
    "        res.append(df.assign(scale=scale))\n",
    "    df = pd.concat(res).reset_index(drop=True)\n",
    "    df = df.astype({x: 'category' for x in ['geoid', 'variable', 'scale']})\n",
    "    df = df['scale is_ses is_derived is_pctile variable geoid value'.split()]\n",
    "    if save:\n",
    "        df.to_parquet(U.mkfile(outpath))\n",
    "    return df\n",
    "\n",
    "ejs = clean_ejs_data(overwrite=0).disp() # t=0:33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f66b857-e513-4dff-b034-b39e840117e2",
   "metadata": {},
   "source": [
    "# POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4e0bf1d-40a5-4b9f-9f5f-93dcfd0e0e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 rows x 3 cols; Memory: 0.0 MiB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>category</th>\n",
       "      <th>fclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>&lt;object&gt;</td>\n",
       "      <td>&lt;object&gt;</td>\n",
       "      <td>&lt;object&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SafeGraph</td>\n",
       "      <td>Education</td>\n",
       "      <td>Elementary and Secondary Schools</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source   category                            fclass\n",
       "    <object>   <object>                          <object>\n",
       "0  SafeGraph  Education  Elementary and Secondary Schools"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(P.data / 'pois/poi_categories.yml', 'rb') as f:\n",
    "    poi_categories = yaml.safe_load(f)\n",
    "\n",
    "poi_classes = []\n",
    "for source, data in poi_categories.items():\n",
    "    for cat, fclasses in data.items():\n",
    "        for fclass in fclasses:\n",
    "            poi_classes.append((source, cat, fclass))\n",
    "poi_classes = Pdf(poi_classes, columns=['source', 'category', 'fclass']).disp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e160a44-e80f-4f89-92a5-e6d82ff79609",
   "metadata": {},
   "source": [
    "## OSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3f99fba-2f43-4b7b-997d-fe9d3a37ca42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---------+------+--------------------+\n",
      "|       id|        name| category|fclass|            geometry|\n",
      "+---------+------------+---------+------+--------------------+\n",
      "|358649475|Black School|Education|school|[01 01 00 00 00 D...|\n",
      "+---------+------------+---------+------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_osm_pois(geocode, categories: Pdf, save=True, overwrite=False):\n",
    "    outfile = P.data / 'pois/osm.parquet'\n",
    "    if outfile.exists() and not overwrite:\n",
    "        return SP.read_parquet(outfile)\n",
    "    fclasses = categories.query('source == \"OSM\"')['fclass'].unique().tolist()\n",
    "    df = osmnx.geometries_from_place(geocode, tags={'amenity': fclasses})\n",
    "    df = df.rename(columns={'amenity': 'fclass'}).to_crs(CRS_M)\n",
    "    df.geometry = df.centroid\n",
    "    df = df[['name', 'fclass', 'geometry']].reset_index()\n",
    "    df = df.rename(columns={'osmid': 'id'}).astype({'id': str})\n",
    "    df = df.merge(categories, on='fclass').to_crs(CRS_DEG)\n",
    "    df = df[['id', 'name', 'category', 'fclass', 'geometry']]\n",
    "    if save:\n",
    "        df.to_parquet(U.mkfile(outfile))\n",
    "    return df\n",
    "\n",
    "osm_pois = get_osm_pois('Indiana', poi_classes, overwrite=0).disp() # t=2:11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190bf798",
   "metadata": {},
   "source": [
    "## SafeGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "007dfd92-ecd2-4d3d-bef3-7700a421c229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+--------------------+--------------------+\n",
      "|                 id|     name|category|              fclass|            geometry|\n",
      "+-------------------+---------+--------+--------------------+--------------------+\n",
      "|222-222@5py-96v-brk|IU Health| Medical|Offices of Physic...|[01 01 00 00 00 D...|\n",
      "+-------------------+---------+--------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_sg_pois(rgn_code, categories, path=SAFEGRAPH / 'us/poi_211104',\n",
    "                save=True, overwrite=False):\n",
    "    outfile = P.data / 'pois/safegraph.parquet'\n",
    "    if outfile.exists() and not overwrite:\n",
    "        return SP.read_parquet(outfile)\n",
    "    df = SP.read_csv(sorted(list((path).glob('*.csv.gz'))), header=True)\n",
    "    if isinstance(rgn_code, str):\n",
    "        df = df.filter(f'region == \"{rgn_code}\"')\n",
    "    cols = {'placekey': 'id', 'location_name': 'name', 'top_category': 'fclass',\n",
    "            'latitude': 'lat', 'longitude': 'lon'}\n",
    "    df = df.select(*[F.col(k).alias(v) for k, v in cols.items()])\n",
    "    cats = categories.query('source == \"SafeGraph\"').drop(columns='source')\n",
    "    df = df.toPandas().merge(cats, on='fclass')\n",
    "    df = mk.geo.pdf2gdf(df, 'lon', 'lat', CRS_DEG)\n",
    "    df = df[['id', 'name', 'category', 'fclass', 'geometry']]\n",
    "    if save:\n",
    "        df.to_parquet(U.mkfile(outfile))\n",
    "    return df\n",
    "\n",
    "sg_pois = get_sg_pois('IN', poi_classes, overwrite=0).disp() # t=0:52"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf2dc38",
   "metadata": {},
   "source": [
    "## Combine POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e8b2e41",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---------+------+--------------------+------+\n",
      "|       id|        name| category|fclass|            geometry|source|\n",
      "+---------+------------+---------+------+--------------------+------+\n",
      "|358649475|Black School|Education|school|[01 01 00 00 00 D...|   OSM|\n",
      "+---------+------------+---------+------+--------------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def combine_pois(save=True, overwrite=False):\n",
    "    outfile = P.data / 'pois/pois.parquet'\n",
    "    if outfile.exists() and not overwrite:\n",
    "        return SP.read_parquet(outfile)\n",
    "    osm = gpd.read_parquet(P.data / 'pois/osm.parquet')\n",
    "    sg = gpd.read_parquet(P.data / 'pois/safegraph.parquet')\n",
    "    pois = pd.concat([\n",
    "        osm.assign(source='OSM'), sg.assign(source='SafeGraph')\n",
    "    ]).reset_index(drop=True)\n",
    "    if save:\n",
    "        pois.to_parquet(U.mkfile(outfile))\n",
    "    return pois\n",
    "\n",
    "pois = combine_pois(overwrite=0).disp() # t-0:03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85f2a41",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2929f3f0",
   "metadata": {},
   "source": [
    "## LEHD/LODES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602cd0d6",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c94e4f50-ca31-42e1-b24a-d1d8e2c68557",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "with open(P.data / 'lehd/columns.yaml', 'rb') as f:\n",
    "    lehd_info = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96f38a6",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdd2746e",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def download_lehd_lodes(dataset='od', job_type='JT00', state='in', part='main',\n",
    "                        segment='S000', year=2019, lodes_version=7,\n",
    "                        aggregate_bg=False, save=True, overwrite=False):\n",
    "    assert lodes_version in [6, 7]\n",
    "    assert dataset in ['od', 'rac', 'wac']\n",
    "    assert part in ['main', 'aux']\n",
    "    assert job_type in [f'JT{i:02}' for i in range(6)]\n",
    "    assert segment in 'S000 SA01 SA02 SA03 SE01 SE02 SE03 SI01 SI02 SI03'.split()\n",
    "    outfile = P.data / f'lehd/lodes/{dataset}.parquet'\n",
    "    if outfile.exists() and not overwrite:\n",
    "        return\n",
    "    root = f'https://lehd.ces.census.gov/data/lodes'\n",
    "    fname = {'od': f'{state}_od_{part}_{job_type}_{year}',\n",
    "             'rac': f'{state}_rac_{segment}_{job_type}_{year}',\n",
    "             'wac': f'{state}_wac_{segment}_{job_type}_{year}'}[dataset]\n",
    "    url = f'{root}/LODES{lodes_version}/{state}/{dataset}/{fname}.csv.gz'\n",
    "    df = pd.read_csv(url).drop(columns='createdate', errors='ignore')\n",
    "    idx_cols = {'od': ['h_geocode', 'w_geocode'],\n",
    "                'rac': ['h_geocode'], 'wac': ['w_geocode']}[dataset]\n",
    "    df = df.astype({col: str for col in idx_cols})\n",
    "    if aggregate_bg:\n",
    "        for col in idx_cols:\n",
    "            df[col] = df[col].str.slice(0, 12)\n",
    "        df = df.groupby(idx_cols).sum().reset_index()\n",
    "    if save:\n",
    "        df.to_parquet(U.mkfile(outfile))\n",
    "    return df\n",
    "\n",
    "download_lehd_lodes('od') # t=0:17\n",
    "download_lehd_lodes('rac') # t=0:05\n",
    "download_lehd_lodes('wac') # t=0:03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693df319",
   "metadata": {},
   "source": [
    "## Economic Tracker\n",
    "GitHub: https://github.com/OpportunityInsights/EconomicTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87e20b3b",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def download_oi_ecotracker_data(overwrite=False):\n",
    "    url = 'https://github.com/OpportunityInsights/EconomicTracker/archive/main.zip'\n",
    "    outfile = P.data / 'economic_tracker/raw_data.zip'\n",
    "    if outfile.exists() and not overwrite:\n",
    "        return\n",
    "    urllib.request.urlretrieve(url, U.mkfile(outfile))\n",
    "\n",
    "# x = download_oi_ecotracker_data(); x # t=0:22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94b081b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
