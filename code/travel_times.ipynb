{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilkit.umni import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Filter eligible OD pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_speeds = {k: v * U.MPH2MPS for k, v in D(\n",
    "    BIKE = 16, DRIVE = 70, TRANSIT = 20, WALK = 3.1\n",
    ").items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = 3600 # 1 hour of travel time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,810,346 rows x 8 cols; Memory: 81.3 MiB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_geoid</th>\n",
       "      <th>src_lon</th>\n",
       "      <th>src_lat</th>\n",
       "      <th>trg_geoid</th>\n",
       "      <th>trg_lon</th>\n",
       "      <th>trg_lat</th>\n",
       "      <th>scale</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>&lt;category&gt;</td>\n",
       "      <td>&lt;float32&gt;</td>\n",
       "      <td>&lt;float32&gt;</td>\n",
       "      <td>&lt;category&gt;</td>\n",
       "      <td>&lt;float32&gt;</td>\n",
       "      <td>&lt;float32&gt;</td>\n",
       "      <td>&lt;category&gt;</td>\n",
       "      <td>&lt;category&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18115</td>\n",
       "      <td>-84.965012</td>\n",
       "      <td>38.950115</td>\n",
       "      <td>18155</td>\n",
       "      <td>-85.036972</td>\n",
       "      <td>38.826218</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>BIKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    src_geoid    src_lon    src_lat   trg_geoid    trg_lon    trg_lat  \\\n",
       "   <category>  <float32>  <float32>  <category>  <float32>  <float32>   \n",
       "0       18115 -84.965012  38.950115       18155 -85.036972  38.826218   \n",
       "\n",
       "        scale        mode  \n",
       "   <category>  <category>  \n",
       "0      COUNTY        BIKE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47,324,439 rows x 8 cols; Memory: 1180.3 MiB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_geoid</th>\n",
       "      <th>src_lon</th>\n",
       "      <th>src_lat</th>\n",
       "      <th>trg_geoid</th>\n",
       "      <th>trg_lon</th>\n",
       "      <th>trg_lat</th>\n",
       "      <th>scale</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>&lt;category&gt;</td>\n",
       "      <td>&lt;float32&gt;</td>\n",
       "      <td>&lt;float32&gt;</td>\n",
       "      <td>&lt;category&gt;</td>\n",
       "      <td>&lt;float32&gt;</td>\n",
       "      <td>&lt;float32&gt;</td>\n",
       "      <td>&lt;category&gt;</td>\n",
       "      <td>&lt;category&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   src_geoid    src_lon    src_lat   trg_geoid    trg_lon    trg_lat  \\\n",
       "  <category>  <float32>  <float32>  <category>  <float32>  <float32>   \n",
       "\n",
       "       scale        mode  \n",
       "  <category>  <category>  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_eligible_odps(rgn, year, speeds=max_speeds, \n",
    "                      max_time=max_time, overwrite=False):\n",
    "    \"\"\"Create candidate OD pairs for zone centroids for each mode by \n",
    "    considering pairs within a maximum distance reachable by each \n",
    "    mode within a given maximum travel time.\n",
    "\n",
    "    Args:\n",
    "        rgn (str): Label of the study region (to get zones table).\n",
    "        year (int): Year of the zones dataset.\n",
    "        speeds (dict): Maximum speed (m/s) of each travel mode.\n",
    "        max_time (float): Maximum duration (s) of travel,\n",
    "            used to compute the radius of reach of each mode.\n",
    "    Returns:\n",
    "        (Pdf): Table of origin (src) and destination (trg) geoid\n",
    "            and coordinates, along with mode and scale.\n",
    "    \"\"\"\n",
    "    outpath = Path(f'../data/od/odp/{rgn.lower()}_{year}.parquet')\n",
    "    if outpath.exists() and not overwrite:\n",
    "        return pd.read_parquet(outpath)\n",
    "    zones = (gpd.read_parquet(f'../data/zones/{rgn.lower()}_{year}.parquet')\n",
    "             .to_crs(CRS_M).assign(geometry=lambda df: df.centroid)\n",
    "             [['geoid', 'scale', 'geometry']].reset_index(drop=1))\n",
    "    xy = mk.geo.gdf2pdf(zones, 'x', 'y', CRS_M)\n",
    "    latlon = mk.geo.gdf2pdf(zones, LON, LAT, CRS_DEG)\n",
    "    zones = (pd.concat([zones, xy, latlon], axis=1)\n",
    "             .drop(columns='geometry').astype(D(x=np.int32, y=np.int32)))\n",
    "    res = []\n",
    "    pbar = tqdm(total=zones['scale'].nunique() * len(speeds))\n",
    "    for scale, df in zones.groupby('scale', sort=False):\n",
    "        tree = cKDTree(df[['x', 'y']])\n",
    "        for mode, speed in speeds.items():\n",
    "            pbar.update()\n",
    "            pbar.set_description(f'{scale} -> {mode}')\n",
    "            odp = tree.query_pairs(max_time * speed, output_type='ndarray')\n",
    "            odp = pd.concat([\n",
    "                df.iloc[odp[:, i]][['geoid', 'lon', 'lat']]\n",
    "                .rename(columns=(kind + '_{}').format).reset_index(drop=1)\n",
    "                for i, kind in enumerate(['src', 'trg'])\n",
    "            ], axis=1).assign(scale=scale, mode=mode)\n",
    "            res.append(odp)\n",
    "    odp = pd.concat(res).reset_index(drop=True).astype({\n",
    "        x: np.float32 for x in ['src_lon', 'src_lat', 'trg_lon', 'trg_lat']\n",
    "    }).astype(CAT)\n",
    "    odp.to_parquet(U.mkfile(outpath))\n",
    "    return odp\n",
    "\n",
    "odpIN10 = get_eligible_odps('IN', 2010, overwrite=0).disp() # t=0:04 (prev. t=3:49)\n",
    "# odpIN20 = get_eligible_odps('IN', 2020, overwrite=0).disp(0) # t=0:05\n",
    "odpMSA10 = get_eligible_odps('MSA', 2010, overwrite=0).disp(0) # t=0:45\n",
    "# odpMSA20 = get_eligible_odps('MSA', 2020, overwrite=0).disp(0) # t=0:55\n",
    "# x = get_eligible_odps('IN', 2010, overwrite=0); x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IN</th>\n",
       "      <th>MSA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BG</th>\n",
       "      <td>3449964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRACT</th>\n",
       "      <td>359603</td>\n",
       "      <td>47320808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COUNTY</th>\n",
       "      <td>779</td>\n",
       "      <td>3631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             IN       MSA\n",
       "scale                    \n",
       "BG      3449964         0\n",
       "TRACT    359603  47320808\n",
       "COUNTY      779      3631"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([v['scale'].value_counts().rename(k) for k, v in [\n",
    "    ('IN', odpIN10), ('MSA', odpMSA10)]], axis=1).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IN</th>\n",
       "      <th>MSA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DRIVE</th>\n",
       "      <td>2674787</td>\n",
       "      <td>29468465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRANSIT</th>\n",
       "      <td>611622</td>\n",
       "      <td>9975978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIKE</th>\n",
       "      <td>478685</td>\n",
       "      <td>7397408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALK</th>\n",
       "      <td>45252</td>\n",
       "      <td>482588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              IN       MSA\n",
       "mode                      \n",
       "DRIVE    2674787  29468465\n",
       "TRANSIT   611622   9975978\n",
       "BIKE      478685   7397408\n",
       "WALK       45252    482588"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([v['mode'].value_counts().rename(k) for k, v in [\n",
    "    ('IN', odpIN10), ('MSA', odpMSA10)]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download from Google\n",
    "The [old disastrous] code is written in `./gdm.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download with OSRM\n",
    "- The [old] code that uses the OSRM web server is written in `$MK/spr_4711/code/_old/osrm_web.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OD pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_osrm_table(rgn, year, scale=None, mode='DRIVE', overwrite=False):\n",
    "#     outpath = Path(f'../data/travel_time/time_{rgn.lower()}_{year}.parquet')\n",
    "#     if outpath.exists() and not overwrite:\n",
    "#         return pd.read_parquet(outpath)\n",
    "#     od_all = (get_eligible_odps(rgn, year).query('mode==\"{}\"{}'.format(\n",
    "#                   mode, f' & scale==\"{scale}\"' if scale else ''))\n",
    "#                   .reset_index(drop=1))\n",
    "#     ##\n",
    "#     od_all = od_all.head(10)\n",
    "#     ##\n",
    "#     idx = np.concatenate([np.arange(0, len(od_all), 100), [len(od_all)]])\n",
    "#     cols = ['geoid', 'lon', 'lat']\n",
    "#     res = []\n",
    "#     for i, j in tqdm(zip(idx[:-1], idx[1:]), total=len(idx) - 1):\n",
    "#         od = od_all.iloc[i: j]\n",
    "#         # waypoints (unique nodes in the OD table)\n",
    "#         wp = pd.concat([od.filter(like=direc).rename(\n",
    "#             columns=lambda x: x.replace(direc + '_', ''))\n",
    "#             for direc in ['src', 'trg']]\n",
    "#         ).drop_duplicates().sort_values('geoid')\n",
    "#         wp = wp.reset_index(drop=1).rename_axis('i').reset_index()\n",
    "#         od = od.merge(wp[['i', 'geoid']].rename(columns='src_{}'.format))\n",
    "#         od = od.merge(wp[['i', 'geoid']].rename(columns='trg_{}'.format))\n",
    "#         xy = ';'.join([f'{r.lon},{r.lat}' for _, r in wp.iterrows()])\n",
    "#         src = ';'.join(od['src_i'].astype(str).unique())\n",
    "#         trg = ';'.join(od['trg_i'].astype(str).unique())\n",
    "#         print(src)\n",
    "#         print(trg)\n",
    "#         print(wp)\n",
    "#         print(od[['src_geoid','trg_geoid','src_i','trg_i']])\n",
    "#         # return od\n",
    "#         base = 'http://router.project-osrm.org/table/v1/driving'\n",
    "#         url = f'{base}/{xy}?sources={src}&destinations={trg}'\n",
    "#         r = requests.get(url)\n",
    "#         df = Pdf(r.json()['durations'])\n",
    "#         return df\n",
    "#         # df = Pdf(r.json()['durations'], index=od.src_geoid, columns=od.trg_geoid)\n",
    "#         df = (df.reset_index().melt('src_geoid')\n",
    "#               .query('value > 0').drop_duplicates().reset_index(drop=1))\n",
    "#         res.append(df)\n",
    "#     res = (pd.concat(res).rename(columns=D(value='time'))\n",
    "#            .astype(D(src_geoid=CAT, trg_geoid=CAT)).reset_index(drop=1))\n",
    "#     res.to_parquet(U.mkfile(outpath))\n",
    "#     return res\n",
    "\n",
    "# x = get_osrm_table('IN', 2010, 'COUNTY', overwrite=1); x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_clust(od, mode=None):\n",
    "#     if isinstance(mode, str):\n",
    "#         od = od[od['mode'] == mode]\n",
    "#     od = Pdf(D(o=od.src_geoid.cat.codes, d=od.trg_geoid.cat.codes))\n",
    "#     g = ig.Graph.TupleList(zip(*od.values.T), directed=False)\n",
    "#     clust = (Seq(dict(enumerate(g.community_label_propagation())), name='node')\n",
    "#              .explode().rename_axis('clust').reset_index().astype(np.int32))\n",
    "#     return clust\n",
    "\n",
    "# cIN = get_clust(odpIN10, 'DRIVE').disp() # t=0:04\n",
    "# # cMSA = get_clust(odpMSA10).disp() # t=0:47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from time import time\n",
    "\n",
    "# import networkx as nx\n",
    "# from scipy.cluster.hierarchy import dendrogram\n",
    "# from sklearn.cluster import KMeans, DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes=1511, edges=245866\n"
     ]
    }
   ],
   "source": [
    "# od = odpIN10.query('scale==\"TRACT\" & mode==\"DRIVE\"')\n",
    "# i2v = dict(enumerate(sorted(set(od.src_geoid) | set(od.trg_geoid))))\n",
    "# v2i = {x: i for i, x in i2v.items()}\n",
    "# od = (Pdf(D(o=od.src_geoid.map(v2i), d=od.trg_geoid.map(v2i)))\n",
    "#       .astype(np.int32).drop_duplicates())\n",
    "# g = ig.Graph.TupleList(zip(*od.values.T), directed=False)\n",
    "# print(f'nodes={g.vcount()}, edges={g.ecount()}')\n",
    "# # # print(g.community_edge_betweenness())\n",
    "# # print(g.community_fastgreedy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1511 245866\n",
      "1510\n"
     ]
    }
   ],
   "source": [
    "# gNx = nx.from_pandas_edgelist(od, 'o', 'd')\n",
    "# print(len(gNx), len(gNx.edges()))\n",
    "# cover = list(nx.algorithms.approximation.min_weighted_vertex_cover(gNx))\n",
    "# print(len(cover))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_durations(od, geoids, mode='driving'):\n",
    "    \"\"\"Obtain the full OD duration matrix for the zones included \n",
    "    in the given `od` table using the OSRM API.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    od : pd.DataFrame\n",
    "        Must have the columns {'src', 'trg'} x {'geoid', 'lon', 'lat'}\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        ...\n",
    "    \"\"\"\n",
    "    od = od.merge(geoids.rename('src_geoid'), on='src_geoid')\n",
    "    od = od.merge(geoids.rename('trg_geoid'), on='trg_geoid')\n",
    "    wp = pd.concat([od.filter(like=direc).rename(\n",
    "        columns=lambda x: x.replace(direc + '_', '')) \n",
    "        for direc in ['src', 'trg']\n",
    "    ]).drop_duplicates(subset='geoid').reset_index(drop=1)\n",
    "    wp = wp.rename_axis('i').reset_index()\n",
    "    od = od.merge(wp[['i', 'geoid']].rename(columns='src_{}'.format))\n",
    "    od = od.merge(wp[['i', 'geoid']].rename(columns='trg_{}'.format))\n",
    "    xy = ';'.join([f'{r.lon},{r.lat}' for _, r in wp.iterrows()])\n",
    "    base = f'http://router.project-osrm.org/table/v1/{mode}'\n",
    "    url = f'{base}/{xy}'\n",
    "    r = requests.get(url)\n",
    "    df = Pdf(r.json()['durations'],\n",
    "             index=wp.geoid.rename('src_geoid'),\n",
    "             columns=wp.geoid.rename('trg_geoid'))\n",
    "    df = df.reset_index().melt('src_geoid', value_name='duration')\n",
    "    df = df.merge(od[['src_geoid', 'trg_geoid']])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_clusters(rgn, year, scale, mode, modes=modes, tmax=3600, nmax=100):\n",
    "#     fname = f'{rgn.lower()}_{year}.parquet'\n",
    "#     zones = (gpd.read_parquet(f'../data/zones/{fname}')\n",
    "#              .query(f'scale == \"{scale}\"').reset_index(drop=1)\n",
    "#              .assign(geometry=lambda df: df.to_crs(CRS_M).centroid))\n",
    "#     xy = mk.geo.gdf2pdf(zones, 'x', 'y', crs=CRS_M)\n",
    "#     latlon = mk.geo.gdf2pdf(zones, 'lon', 'lat', crs=CRS_DEG)\n",
    "#     zones = pd.concat([zones['geoid'], latlon, xy], axis=1)\n",
    "#     odp = (pd.read_parquet(f'../data/travel_time/odps_{fname}')\n",
    "#            .query(f'scale == \"{scale}\" & mode == \"{mode}\"')\n",
    "#            .drop(columns=['scale', 'mode']).reset_index(drop=1))\n",
    "#     dmax = tmax * modes.loc[mode].max_speed\n",
    "#     model = AgglomerativeClustering(n_clusters=None, distance_threshold=dmax)\n",
    "#     zones['clust'] = model.fit(xy).labels_\n",
    "#     durations = []\n",
    "#     for clust, df in tqdm(zones.groupby('clust')):\n",
    "#         dur = get_durations(odp, df['geoid'].head(nmax))\n",
    "#         durations.append(dur.assign(clust=clust))\n",
    "#         idx = odp.merge(dur, on=('src_geoid', 'trg_geoid')).index\n",
    "#         if clust == 1:\n",
    "#             return dur\n",
    "#             return odp.merge(dur)\n",
    "#         odp.drop(idx, inplace=True)\n",
    "#         return odp\n",
    "#     dur = pd.concat(durations).reset_index()\n",
    "#     return dur\n",
    "\n",
    "# x = get_clusters('IN', 2010, 'COUNTY', 'DRIVE'); x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_matrix(base_url, nodes):\n",
    "    url = '{}/{}'.format(base_url, ';'.join([\n",
    "        f'{x},{y}' for x, y in zip(nodes['lon'], nodes['lat'])]))\n",
    "    dur = Pdf(requests.get(url).json()['durations'],\n",
    "              index=nodes['geoid'].rename('src_geoid'),\n",
    "              columns=nodes['geoid'].rename('trg_geoid'))\n",
    "    return dur.reset_index().melt('src_geoid', value_name='duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(rgn, year, scale, mode, modes=modes, batch_size=100, \n",
    "                 tmax=3600, overwrite=False):\n",
    "    outpath = Path('../data/travel_time/osrm/{}_{}_{}_{}.parquet'.format(\n",
    "        rgn.lower(), year, scale.lower(), mode.lower()))\n",
    "    if outpath.exists() and not overwrite:\n",
    "        return pd.read_parquet(outpath)\n",
    "    # edgelist (OD pairs)\n",
    "    E = pd.read_parquet(f'../data/travel_time/odps_{rgn.lower()}_{year}.parquet')\n",
    "    E = E[(E['scale'] == scale) & (E['mode'] == mode)].reset_index(drop=1)\n",
    "    E = E.drop(columns=['scale', 'mode'])\n",
    "    # add edges in the reverse direction\n",
    "    src = E.filter(like='src').rename(columns=lambda x: x.replace('src_', ''))\n",
    "    trg = E.filter(like='trg').rename(columns=lambda x: x.replace('trg_', ''))\n",
    "    E_flip = pd.concat([src.rename(columns='trg_{}'.format), \n",
    "                        trg.rename(columns='src_{}'.format)], axis=1)\n",
    "    E = pd.concat([E, E_flip]).reset_index(drop=1)#.rename_axis('eid')\n",
    "    print(E.shape)\n",
    "    # unique nodes\n",
    "    V = pd.concat([src, trg]).drop_duplicates(subset='geoid')\n",
    "    V = V.sort_values('geoid').reset_index(drop=1)\n",
    "    V_gdf = mk.geo.pdf2gdf(V, crs=CRS_DEG).to_crs(CRS_M)\n",
    "    V = pd.concat([V, mk.geo.gdf2pdf(V_gdf, 'x', 'y', CRS_M)], axis=1)\n",
    "    V = V.rename_axis('vid')\n",
    "    # create clusters based on max. distance reachable by the mode\n",
    "    dmax = tmax * modes.loc[mode].max_speed\n",
    "    # model = AgglomerativeClustering(n_clusters=None, distance_threshold=dmax)\n",
    "    min_samp = D(COUNTY=2, TRACT=2, BG=50)[scale]\n",
    "    model = DBSCAN(eps=dmax, min_samples=min_samp)\n",
    "    # nmax, step = D(COUNTY=(100, 10), TRACT=(1500, 100), BG=(10000, 1000))[scale]\n",
    "    # for nclust in tqdm(np.arange(0, nmax, step)[1:]):\n",
    "        # model = AgglomerativeClustering(n_clusters=nclust)\n",
    "    # model = KMeans(nclust)\n",
    "    V['clust'] = model.fit(V[['x', 'y']]).labels_\n",
    "    durations = []\n",
    "    mode_lab = D(DRIVE='driving', BIKE='bike', WALK='walk')[mode]\n",
    "    base_url = f'http://router.project-osrm.org/table/v1/{mode_lab}'\n",
    "    for clust, V2 in V.groupby('clust'):                                ## for each cluster\n",
    "        idx = list(np.arange(0, len(V2) + 1, batch_size)) + [len(V2)]\n",
    "        for i, j in zip(idx[:-1], idx[1:]):                             ## for each batch\n",
    "            # iters += 1\n",
    "            V3 = V2.iloc[i: j].reset_index(drop=1)\n",
    "            try:\n",
    "                url = base_url + '/' + ';'.join([\n",
    "                    f'{x},{y}' for x, y in zip(V3.lon, V3.lat)])\n",
    "                # dur = requests.get(url).json()['durations']\n",
    "                dur = Pdf(1, index=V3.geoid.rename('src_geoid'),\n",
    "                            columns=V3.geoid.rename('trg_geoid'))\n",
    "                dur = dur.reset_index().melt('src_geoid', value_name='duration')\n",
    "                E2 = E.merge(dur, 'left').dropna(subset='duration')\n",
    "                durations.append(E2.assign(clust=clust))\n",
    "                E.drop(E2.index, inplace=True, errors='ignore')\n",
    "                # Efinal = E.drop(E2.index, errors='ignore')\n",
    "            except Exception as e:\n",
    "                print(f'ERROR={e}, region={rgn}, year={year}, scale={scale}',\n",
    "                    f'mode={mode}, cluster={clust}, nnodes={len(V2)}, batch={i}')\n",
    "    print(f'leftover edges = {len(E)}')\n",
    "    # print(f'clusters={nclust}, iterations={iters}, remaining_edges={len(Efinal)}')\n",
    "    # dur = pd.concat(durations).reset_index(drop=1)\n",
    "    # dur.to_parquet(U.mkfile(outpath))\n",
    "    # return dur\n",
    "\n",
    "# %time print('IN county'); get_clusters('IN', 2010, 'COUNTY', 'DRIVE') # t=2:13\n",
    "# %time print('IN tract'); get_clusters('IN', 2010, 'TRACT', 'DRIVE') # 6:50\n",
    "# %time print('IN bg'); get_clusters('IN', 2010, 'BG', 'DRIVE') # t=12:54\n",
    "# %time print('MSA county'); get_clusters('MSA', 2010, 'COUNTY', 'DRIVE') # t=11:05\n",
    "# %time print('MSA tract'); get_clusters('MSA', 2010, 'TRACT', 'DRIVE')\n",
    "# x = get_clusters('IN', 2010, 'COUNTY', 'DRIVE', overwrite=1); x\n",
    "x = get_clusters('IN', 2010, 'TRACT', 'DRIVE', overwrite=1); x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odpIN10.query('mode==\"DRIVE\"')['scale'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odpIN10['mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odpMSA10['mode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_eligible_odps_one_region(big_df, max_duration=max_duration, \n",
    "#                                  max_speeds=max_speeds, workers=4):\n",
    "#     res = []\n",
    "#     for _, df2 in big_df.groupby('scale', sort=False):\n",
    "#         if len(df2) <= 1: continue\n",
    "#         tree = cKDTree(df2[['x', 'y']])\n",
    "#         df = []\n",
    "#         for mode, max_speed in max_speeds.items(): ## mode (bike/drive...)\n",
    "#             radius = max_speed * max_duration\n",
    "#             odp = tree.query_ball_point(df2[['x', 'y']], radius, workers=workers)\n",
    "#             odp = sum([[(i, x) for x in p] for i, p in enumerate(odp)], [])\n",
    "#             odp = Pdf(odp, columns=['src_id', 'trg_id']).assign(mode=mode)\n",
    "#             df.append(odp)\n",
    "#         df = pd.concat(df).reset_index(drop=True)\n",
    "#         res.append(pd.concat([df[['mode']]] + [\n",
    "#             df2.iloc[df.pop(f'{kind}_id')][['geoid', LON, LAT]]\n",
    "#             .rename(columns=(kind + '_{}').format).reset_index(drop=True)\n",
    "#             for kind in ['src', 'trg']\n",
    "#         ], axis=1))\n",
    "#     return pd.concat(res).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_eligible_odps(zones, imp_states=[], imp_cbsas=[],\n",
    "#                       njobs=24, overwrite=False):\n",
    "#     \"\"\"\n",
    "#     Filter zone OD pairs for the 3 spatial scales by mode within either \n",
    "#     the given states or the given CBSAs by limiting them within the \n",
    "#     circle induced by the maximum modal distance coverable within the \n",
    "#     given maximum duration.\n",
    "#     - zones: Gdf\n",
    "#         Zones table for all the US and all scales\n",
    "#     - imp_states: list[str]\n",
    "#         List of US states to be included (full names only)\n",
    "#     - imp_cbsas: list[str]\n",
    "#         List of the FIPS codes of the CBSAs to be included\n",
    "#     - max_duration: int\n",
    "#         Maximum duration of travel in seconds\n",
    "#     - max_speeds: dict\n",
    "#         Maximum speed for each mode in m/s\n",
    "#     - workers: int\n",
    "#         Number of workers for parallel spatial tree search\n",
    "#     \"\"\"\n",
    "#     outpath = Path(f'../data/deterrence/od_pairs.parquet')\n",
    "#     if outpath.exists() and not overwrite:\n",
    "#         return pd.read_parquet(outpath)\n",
    "#     zones = (zones.assign(geometry=zones.to_crs(CRS_M).centroid)\n",
    "#              .assign(x=lambda df: df.geometry.x, y=lambda df: df.geometry.y)\n",
    "#              .to_crs(CRS_DEG)\n",
    "#              .assign(lon=lambda df: df.geometry.x, lat=lambda df: df.geometry.y)\n",
    "#              .astype({'lon': np.float32, 'lat': np.float32})\n",
    "#              [['geoid', 'scale', 'state', 'cbsa', 'x', 'y', 'lon', 'lat']])\n",
    "#     dfs = []\n",
    "#     for col, rgns in [('cbsa', imp_cbsas), ('state', imp_states)]:\n",
    "#         for _, df in zones[zones[col].isin(rgns)].groupby(col):\n",
    "#             if len(df) <= 1: continue\n",
    "#             dfs.append(df[['geoid', 'scale', 'x', 'y', 'lon', 'lat']])\n",
    "#     odp = pqdm(dfs, get_eligible_odps_one_region, n_jobs=njobs)\n",
    "#     odp = (pd.concat(odp).query('src_geoid != trg_geoid')\n",
    "#            .drop_duplicates(subset=['src_geoid', 'trg_geoid', 'mode'])\n",
    "#            .dropna().reset_index(drop=True).astype(CAT))\n",
    "#     odp.to_parquet(U.mkfile(outpath), compression='gzip')\n",
    "#     return odp\n",
    "\n",
    "# od10 = get_eligible_odps(zones10, ['Indiana'], list(imp_cbsas.cbsa), \n",
    "#                          overwrite=0).disp() # t=9:46:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = (od10.assign(scale=od10.src_geoid.str.len()\n",
    "#                  .map({5: 'county', 11: 'tract', 12: 'bg'}))\n",
    "#      .groupby(['scale', 'mode']).size().rename('n_odp').reset_index()); x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.groupby('scale')['n_odp'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones10['scale'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mk11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
